{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt # rms = sqrt(mean_squared_error(y_true, y_predicted))\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# linear regression models\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet,BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# cross val, k-folds\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Param Search\n",
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Best Parameters: {'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "grid_param = {'normalize':[True,False]}\n",
    "\n",
    "'''grid_param = {  \n",
    "    'n_estimators': [100, 300, 500, 800, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False]\n",
    "}'''\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator= lr,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X,Y)\n",
    "\n",
    "best_parameters = grid_search.best_params_  \n",
    "print(\"Linear Regression Best Parameters:\",best_parameters)  \n",
    "\n",
    "# Output Example:\n",
    "#{'bootstrap': True, 'criterion': 'gini', 'n_estimators': 1000}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Ridge Best Parameters: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'lambda_1': 1e-07, 'lambda_2': 1e-06, 'n_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "grid_param = {\n",
    "    'n_iter':[100,300,500],\n",
    "    'alpha_1':[1.e-6,1.e-7],\n",
    "    'alpha_2':[1.e-6,1.e-7],\n",
    "    'lambda_1':[1.e-6,1.e-7],\n",
    "    'lambda_2':[1.e-6,1.e-7],\n",
    "}\n",
    "\n",
    "br = BayesianRidge()\n",
    "\n",
    "grid_search = GridSearchCV(estimator= br,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X,Y)\n",
    "\n",
    "best_parameters = grid_search.best_params_  \n",
    "print(\"Bayesian Ridge Best Parameters:\",best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Best Parameters: {'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 6}\n"
     ]
    }
   ],
   "source": [
    "grid_param = {\n",
    "    'max_depth':[None,2,4],\n",
    "    'min_samples_split':[2,4,6],\n",
    "    'min_samples_leaf':[1,2,3],\n",
    "    'max_features':[\"auto\",\"sqrt\",\"log2\"]\n",
    "}\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator= dtr,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X,Y)\n",
    "\n",
    "best_parameters = grid_search.best_params_  \n",
    "print(\"Decision Tree Best Parameters:\",best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Parameters: {'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "grid_param = {\n",
    "    'n_estimators':[10,100,500],\n",
    "    'max_depth':[2],\n",
    "    'min_samples_split':[6],\n",
    "    'min_samples_leaf':[2],\n",
    "    'max_features':[\"auto\",\"sqrt\",\"log2\"]\n",
    "}\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator= rfr,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X,Y)\n",
    "\n",
    "best_parameters = grid_search.best_params_ \n",
    "\n",
    "print(\"Random Forest Best Parameters:\",best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Best Parameters: {'C': 1, 'degree': 4, 'gamma': 0.2, 'kernel': 'poly', 'max_iter': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rohithsoorampc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_param = {\n",
    "    'C':[0.1,1],\n",
    "    'max_iter':[500,1000],\n",
    "    'kernel':['rbf','linear','poly'],\n",
    "    'gamma':[0.01,0.1,0.2],\n",
    "    'degree':[3,4],\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "grid_search = GridSearchCV(estimator= svr,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X,Y)\n",
    "\n",
    "best_parameters = grid_search.best_params_ \n",
    "\n",
    "print(\"SVR Best Parameters:\",best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Best Parameters: {'learning_rate': 2, 'loss': 'square', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "grid_param = {\n",
    "    'n_estimators':[30,50,100],\n",
    "    'learning_rate':[0.5,1,2],\n",
    "    'loss':['linear','square']\n",
    "}\n",
    "\n",
    "abr = AdaBoostRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator= abr,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X,Y)\n",
    "\n",
    "best_parameters = grid_search.best_params_ \n",
    "\n",
    "print(\"Ada Boost Best Parameters:\",best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Best Parameters: {'learning_rate': 0.05, 'loss': 'ls', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "grid_param = {\n",
    "    'n_estimators':[100,300],\n",
    "    'learning_rate':[0.05,0.1,0.2],\n",
    "    'loss':['ls','huber'],\n",
    "    'max_features':[\"auto\",\"sqrt\",\"log2\"],\n",
    "    'max_depth':[2,3]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator= gbr,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X,Y)\n",
    "\n",
    "best_parameters = grid_search.best_params_ \n",
    "\n",
    "print(\"Gradient Boost Best Parameters:\",best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting\n",
    "\n",
    "-----------------  Best Features  --------------------\n",
    "\n",
    "Linear Regression Best Parameters: {'normalize': False}\n",
    "\n",
    "Bayesian Ridge Best Parameters: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'lambda_1': 1e-07, 'lambda_2': 1e-06, 'n_iter': 100}\n",
    "\n",
    "Decision Tree Best Parameters: {'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 6}\n",
    "\n",
    "Random Forest Best Parameters: {'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 100}\n",
    "\n",
    "SVR Best Parameters: {'C': 1, 'degree': 4, 'gamma': 0.2, 'kernel': 'poly', 'max_iter': 1000}\n",
    "\n",
    "Ada Boost Best Parameters: {'learning_rate': 2, 'loss': 'square', 'n_estimators': 30}\n",
    "\n",
    "Gradient Boost Best Parameters: {'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 100}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model = LinearRegression()\n",
    "br_model = BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-07, lambda_2=1e-06, n_iter=100)\n",
    "dtr_model = DecisionTreeRegressor(max_depth=2, max_features='sqrt', min_samples_leaf=2, min_samples_split=6)\n",
    "rfr_model = RandomForestRegressor(max_depth=2, max_features='sqrt', min_samples_leaf=2, min_samples_split=6,n_estimators=100)\n",
    "svr_model = SVR()#SVR(C=1, degree=4, gamma=0.2, kernel='poly',max_iter=1000)\n",
    "abr_model = AdaBoostRegressor(learning_rate=2, loss='square',n_estimators=30)\n",
    "gbr_model = GradientBoostingRegressor(learning_rate=0.05, loss='ls', max_depth=2, max_features='log2',n_estimators=100)\n",
    "gbr_model_2 = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rohithsoorampc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_model.fit(X_train,y_train)\n",
    "br_model.fit(X_train,y_train)\n",
    "dtr_model.fit(X_train,y_train)\n",
    "rfr_model.fit(X_train,y_train)\n",
    "svr_model.fit(X_train,y_train)\n",
    "abr_model.fit(X_train,y_train)\n",
    "gbr_model.fit(X_train,y_train)\n",
    "gbr_model_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Scores- rmse: 2928091.7919110986  r2: -59510.840122542046\n",
      "Bayesian Ridge Scores- rmse: 11920.754919688095  r2: 0.013626210673391093\n",
      "Decision Tree Scores- rmse: 11947.594472475916  r2: 0.009179573786463835\n",
      "Random Forest Scores- rmse: 11935.392459437538  r2: 0.011202379307651\n",
      "Support Vector Regression Scores- rmse: 12172.597921347851  r2: -0.028491148500422225\n",
      "Ada Boost Regression Scores- rmse: 12005.18422077273  r2: -0.00039534473426550143\n",
      "Gradient Boost Regression Scores- rmse: 11909.96268477511  r2: 0.015411392737915697\n",
      "Gradient Boost(No tuning) Regression Scores- rmse: 12126.166016669507  r2: -0.02065983363208912\n"
     ]
    }
   ],
   "source": [
    "y_pred = lm_model.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Linear Regression Scores- rmse:\",rmse,\" r2:\",r2)\n",
    "\n",
    "y_pred = br_model.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Bayesian Ridge Scores- rmse:\",rmse,\" r2:\",r2)\n",
    "\n",
    "y_pred = dtr_model.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Decision Tree Scores- rmse:\",rmse,\" r2:\",r2)\n",
    "\n",
    "y_pred = rfr_model.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Scores- rmse:\",rmse,\" r2:\",r2)\n",
    "\n",
    "y_pred = svr_model.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Support Vector Regression Scores- rmse:\",rmse,\" r2:\",r2)\n",
    "\n",
    "y_pred = abr_model.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Ada Boost Regression Scores- rmse:\",rmse,\" r2:\",r2)\n",
    "\n",
    "y_pred = gbr_model.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Gradient Boost Regression Scores- rmse:\",rmse,\" r2:\",r2)\n",
    "\n",
    "y_pred = gbr_model_2.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Gradient Boost(No tuning) Regression Scores- rmse:\",rmse,\" r2:\",r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBT Regressor - Finding Params - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grid_param = {\\n    \\'n_estimators\\':[10,50,100,300],\\n    \\'learning_rate\\':[0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\\n    \\'min_samples_split\\': [1,2,3,4,5,6,7,8],\\n    \\'min_samples_leaf\\': [1,2,3,4,5,6,7,8],\\n    \\'loss\\':[\\'ls\\',\\'huber\\', \\'quantile\\'],\\n    \\'criterion\\': [\"friedman_mse\",  \"mae\"]\\n    \\'max_features\\':[\"sqrt\",\"log2\"],\\n    \\'max_depth\\':[2,3,5,7]\\n    \\'subsample\\':[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\\n    \\'alpha\\':[0.5,0.7,0.9]\\n}\\n\\ngbr = GradientBoostingRegressor()\\n\\ngrid_search = GridSearchCV(estimator= gbr,  \\n                     param_grid=grid_param,\\n                     scoring=\\'neg_mean_squared_error\\',\\n                     cv=5,\\n                     n_jobs=-1)\\n\\ngrid_search.fit(X_train,y_train) # X,y\\n\\nbest_parameters = grid_search.best_params_ \\n\\nprint(\"Gradient Boost Best Parameters:\",best_parameters)'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''grid_param = {\n",
    "    'n_estimators':[10,50,100,300],\n",
    "    'learning_rate':[0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    'min_samples_split': [1,2,3,4,5,6,7,8],\n",
    "    'min_samples_leaf': [1,2,3,4,5,6,7,8],\n",
    "    'loss':['ls','huber', 'quantile'],\n",
    "    'criterion': [\"friedman_mse\",  \"mae\"]\n",
    "    'max_features':[\"sqrt\",\"log2\"],\n",
    "    'max_depth':[2,3,5,7]\n",
    "    'subsample':[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    'alpha':[0.5,0.7,0.9]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator= gbr,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train,y_train) # X,y\n",
    "\n",
    "best_parameters = grid_search.best_params_ \n",
    "\n",
    "print(\"Gradient Boost Best Parameters:\",best_parameters)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.regularizers import l1\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model_Neural = Sequential()\n",
    "\n",
    "# get # of columns in training data\n",
    "cols = X_train.shape[1]\n",
    "\n",
    "#adding layers\n",
    "model_Neural.add(Dense(58, activation='relu', input_shape=(cols,)))\n",
    "model_Neural.add(Dense(30, activation='relu'))\n",
    "model_Neural.add(Dense(10, activation='relu'))\n",
    "model_Neural.add(Dense(1))\n",
    "\n",
    "model_Neural.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "\n",
    "model_Neural.fit(X_train, y_train, validation_split=0.2, epochs=200, callbacks=[early_stopping_monitor])\n",
    "\n",
    "predictions = model_Neural.predict(X_test)\n",
    "print(\"R2 score:\",r2_score(y_test, predictions))\n",
    "rms = sqrt(mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE Score:\",rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'best_model.pkl'\n",
    "pickle.dump(gbr_model_2, open(filename, 'wb')) \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
